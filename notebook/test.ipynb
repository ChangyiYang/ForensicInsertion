{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2eedb62",
   "metadata": {},
   "source": [
    "# LangChain Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0e1a15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¤– å›ç­”ï¼š Hello! How can I assist you today?\n",
      "ğŸ¤– å›ç­”ï¼š I am based on OpenAI's GPT-4 model, which is a state-of-the-art language model designed to understand and generate human-like text based on the input it receives. If you have any questions or need assistance, feel free to ask!\n",
      "ğŸ¤– å›ç­”ï¼š Hello! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import HumanMessage\n",
    "\n",
    "# ä» .env åŠ è½½ç¯å¢ƒå˜é‡\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# æ£€æŸ¥æ˜¯å¦æˆåŠŸè·å– key\n",
    "if not api_key:\n",
    "    raise ValueError(\"æ‰¾ä¸åˆ° OPENAI_API_KEYï¼Œè¯·ç¡®è®¤ .env æ–‡ä»¶æ˜¯å¦å­˜åœ¨å¹¶æ­£ç¡®é…ç½®ã€‚\")\n",
    "\n",
    "# åˆå§‹åŒ– LLM\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o\", openai_api_key=api_key)\n",
    "\n",
    "# ç®€å•å¯¹è¯å¾ªç¯\n",
    "while True:\n",
    "    user_input = input(\"\\nä½ è¯´ï¼š\")\n",
    "    if user_input.lower() in {\"exit\", \"quit\"}:\n",
    "        break\n",
    "    response = llm([HumanMessage(content=user_input)])\n",
    "    print(\"ğŸ¤– å›ç­”ï¼š\", response.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5a72397c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_generate_search_queries = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "You are a helpful assistant that generates realistic human-like search queries from user activity descriptions.\\\n",
    "\n",
    "Your job is to imagine what the user might have searched on a search engine (e.g., Google) to complete their described activity.\\\n",
    "\n",
    "Don't copy phrases directly from the activity. \\\n",
    "Instead, expand and interpret it to generate varied and specific search queries.\\\n",
    "Include possible subtopics and related aspects.\\\n",
    "Use natural human phrasing.\\\n",
    "\n",
    "Only return a plain Python list of strings. No extra text.\\\n",
    "\n",
    "---\n",
    "\n",
    "Example 1:\\\n",
    "User activity: \"I was reading articles about climate change and polar bears\"\\\n",
    "Output: [\"effects of climate change\", \"how polar bears survive melting ice\", \"arctic food chain\", \"polar bear population decline\"]\\\n",
    "\n",
    "Example 2:\\\n",
    "User activity: \"I was watching videos about different kinds of cats\"\\\n",
    "Output: [\"cutest cat breeds ranked\", \"funny cat behavior\", \"maine coon vs ragdoll cat\", \"how to care for kittens\", \"most popular cats on YouTube\"]\\\n",
    "\n",
    "---\n",
    "\n",
    "Now try this:\\\n",
    "\n",
    "User activity: \"{activity}\"\\\n",
    "\n",
    "Output:\\\n",
    "\"\"\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5f79ad35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import HumanMessage\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load env and OpenAI key\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o\", openai_api_key=api_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "29446a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "search_query_chain = LLMChain(\n",
    "    prompt=prompt_generate_search_queries,\n",
    "    llm=llm,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "47182659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```python\n",
      "[\"top cat articles April 2023\", \"funniest cat videos April 2023\", \"popular cat breeds 2023\", \"cat behavior insights April\", \"viral cat videos compilation April 2023\"]\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "activity = \"I want to recreate my activity from April 12 where I was reading cat-related articles and watching funny cat videos.\"\n",
    "\n",
    "result = search_query_chain.run(\n",
    "    activity=activity\n",
    ")\n",
    "\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09729b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-demo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
